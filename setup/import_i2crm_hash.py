#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚ Ñ hash-based Ð´ÐµÐ´ÑƒÐ¿Ð»Ð¸ÐºÐ°Ñ†Ð¸ÐµÐ¹ (Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ð´Ð°Ð¶Ðµ ÐµÑÐ»Ð¸ Ð² Ð‘Ð” ÐµÑÑ‚ÑŒ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ñ‹)
"""
import sys, io
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

import pandas as pd
import psycopg2
from psycopg2.extras import execute_batch
import uuid
from datetime import datetime
from pathlib import Path
import time
import hashlib

CONNECTION_STRING = 'postgresql://neondb_owner:npg_cHIT9Kxfk1Am@ep-rough-heart-ahnybmq0-pooler.c-3.us-east-1.aws.neon.tech/neondb?sslmode=require'

def get_conn():
    return psycopg2.connect(CONNECTION_STRING, connect_timeout=10)

def parse_context(s):
    s_lower = s.lower()
    channel = 'telegram' if 'telegram' in s_lower else 'whatsapp' if 'whatsapp' in s_lower else 'unknown'
    direction = 'incoming' if '(Ð²Ñ…)' in s else 'outgoing'
    return channel, direction

def parse_ts(s):
    try:
        return datetime.strptime(str(s), '%d.%m.%Y %H:%M:%S')
    except:
        return None

def msg_hash(channel, client, timestamp, content):
    """Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ hash ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ"""
    key = f"{channel}_{client}_{timestamp}_{content[:100]}"
    return hashlib.md5(key.encode()).hexdigest()

print("="*80)
print("ðŸš€ Ð˜ÐœÐŸÐžÐ Ð¢ i2crm (hash-based Ð´ÐµÐ´ÑƒÐ¿Ð»Ð¸ÐºÐ°Ñ†Ð¸Ñ)")
print("="*80)

# 1. ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ hash ÑƒÐ¶Ðµ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹
print("\nðŸ“Š Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹...")
conn = get_conn()
cur = conn.cursor()
cur.execute("""
    SELECT channel, client_identifier, sent_at, substring(content, 1, 100)
    FROM i2crm_messages
""")
existing = set()
for row in cur.fetchall():
    h = msg_hash(row[0], row[1], row[2], row[3] or '')
    existing.add(h)
cur.close()
conn.close()
print(f"âœ… Ð£Ð¶Ðµ Ð² Ð‘Ð”: {len(existing):,} ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹")

# 2. Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ñ„Ð°Ð¹Ð»Ñ‹
print("\nðŸ“– Ð§Ñ‚ÐµÐ½Ð¸Ðµ Excel Ñ„Ð°Ð¹Ð»Ð¾Ð²...")
excel_dir = Path("excel")
files = sorted(excel_dir.glob("*.xlsx"))

all_data = []
for f in files:
    print(f"   â€¢ {f.name}")
    df = pd.read_excel(f)
    
    required = ['ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚', 'ÐÐ°Ð¿Ð¸ÑÐ°Ð½Ð¾', 'ÐšÐ»Ð¸ÐµÐ½Ñ‚', 'Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ']
    if not all(c in df.columns for c in required):
        print(f"     âš ï¸  ÐŸÑ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½")
        continue
    
    df[['channel','direction']] = df['ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚'].apply(lambda x: pd.Series(parse_context(x)))
    df['sent_at'] = df['ÐÐ°Ð¿Ð¸ÑÐ°Ð½Ð¾'].apply(parse_ts)
    df = df.rename(columns={'ÐšÐ°Ð½Ð°Ð»':'channel_name','ÐšÐ»Ð¸ÐµÐ½Ñ‚':'client_identifier','Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ':'content','ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚':'raw_context'})
    df = df.dropna(subset=['client_identifier','sent_at'])
    
    all_data.append(df)
    print(f"     Ð’Ð°Ð»Ð¸Ð´Ð½Ñ‹Ñ…: {len(df):,}")

combined_df = pd.concat(all_data, ignore_index=True)
print(f"\nâœ… Ð’ÑÐµÐ³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹: {len(combined_df):,}")

# 3. Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÐ¼ ÑƒÐ¶Ðµ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ
print("\nðŸ” Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð²...")
combined_df['hash'] = combined_df.apply(
    lambda r: msg_hash(r['channel'], r['client_identifier'], r['sent_at'], str(r['content'])[:100] if pd.notna(r['content']) else ''),
    axis=1
)

before_filter = len(combined_df)
combined_df = combined_df[~combined_df['hash'].isin(existing)]
after_filter = len(combined_df)

print(f"Ð”Ð¾ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ð¸: {before_filter:,}")
print(f"ÐŸÐ¾ÑÐ»Ðµ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ð¸: {after_filter:,}")
print(f"ÐžÑ‚Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð¾Ð²Ð°Ð½Ð¾ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð²: {before_filter - after_filter:,}")

if after_filter == 0:
    print("\nâœ… Ð’Ð¡Ð• Ð¡ÐžÐžÐ‘Ð©Ð•ÐÐ˜Ð¯ Ð£Ð–Ð• Ð˜ÐœÐŸÐžÐ Ð¢Ð˜Ð ÐžÐ’ÐÐÐ«!")
    exit(0)

# 4. Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼/Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¸
print("\nðŸ“‹ ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð²...")
conn = get_conn()
cur = conn.cursor()
cur.execute("SELECT channel, client_identifier, id FROM i2crm_conversations")
conv_map = {(r[0],r[1]):r[2] for r in cur.fetchall()}
cur.close()
conn.close()

combined_df['conversation_id'] = combined_df.apply(lambda r: conv_map.get((r['channel'],r['client_identifier'])), axis=1)
combined_df = combined_df.dropna(subset=['conversation_id'])

# 5. Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚ ÐÐžÐ’Ð«Ð¥ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹
print("\nðŸ’¬ Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚ Ð½Ð¾Ð²Ñ‹Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹...")
print(f"Ðš Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ñƒ: {len(combined_df):,}")

CHUNK = 100
imported = 0
errors = 0

insert_query = '''
    INSERT INTO i2crm_messages 
    (id,conversation_id,channel,channel_name,client_identifier,content,direction,sent_at,raw_context) 
    VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s)
'''

total = len(combined_df)
for start in range(0, total, CHUNK):
    chunk = combined_df.iloc[start:start+CHUNK]
    msgs = [(str(uuid.uuid4()),r['conversation_id'],r['channel'],r['channel_name'],
             r['client_identifier'],str(r['content'])[:10000] if pd.notna(r['content']) else '',
             r['direction'],r['sent_at'],str(r['raw_context'])[:1000] if pd.notna(r['raw_context']) else '')
            for _,r in chunk.iterrows()]
    
    try:
        conn = get_conn()
        cur = conn.cursor()
        cur.executemany(insert_query, msgs)
        conn.commit()
        cur.close()
        conn.close()
        
        imported += len(msgs)
        
        if start % 5000 == 0:
            pct = (start / total) * 100
            print(f"   {start:,} / {total:,} ({pct:.1f}%)")
            
    except Exception as e:
        errors += 1
        print(f"   âŒ {e}")
        try:
            conn.close()
        except:
            pass
        if errors > 10:
            break
        time.sleep(1)

print(f"\nâœ… Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾: {imported:,}")
print(f"ÐžÑˆÐ¸Ð±Ð¾Ðº: {errors}")
print("="*80)

