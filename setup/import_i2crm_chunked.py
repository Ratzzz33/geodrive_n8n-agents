#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ò–º–ø–æ—Ä—Ç i2crm —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –Ω–∞ —á–∞–Ω–∫–∏ (–¥–ª—è –æ–±—Ö–æ–¥–∞ Neon timeout)
"""

import sys
import io
import pandas as pd
import os
from pathlib import Path
from datetime import datetime
import psycopg2
from psycopg2.extras import execute_batch
import uuid
import time

if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

CONNECTION_STRING = "postgresql://neondb_owner:npg_cHIT9Kxfk1Am@ep-rough-heart-ahnybmq0-pooler.c-3.us-east-1.aws.neon.tech/neondb?sslmode=require"

def parse_context(context_str):
    context_lower = context_str.lower()
    if 'telegram' in context_lower:
        channel = 'telegram'
    elif 'whatsapp' in context_lower:
        channel = 'whatsapp'
    else:
        channel = 'unknown'
    
    if '(–≤—Ö)' in context_str or 'incoming' in context_lower:
        direction = 'incoming'
    elif '(–∏—Å—Ö)' in context_str or 'outgoing' in context_lower:
        direction = 'outgoing'
    else:
        direction = 'unknown'
    
    return channel, direction

def parse_timestamp(ts_str):
    try:
        return datetime.strptime(ts_str, '%d.%m.%Y %H:%M:%S')
    except:
        return None

def process_excel_file(filepath):
    print(f"üìñ {os.path.basename(filepath)}")
    df = pd.read_excel(filepath)
    print(f"   –ü—Ä–æ—á–∏—Ç–∞–Ω–æ: {len(df):,}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ —Ñ–∞–π–ª –æ—Ç i2crm (–¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏)
    required_cols = ['–ö–æ–Ω—Ç–µ–∫—Å—Ç', '–ù–∞–ø–∏—Å–∞–Ω–æ', '–ö–ª–∏–µ–Ω—Ç', '–°–æ–¥–µ—Ä–∂–∏–º–æ–µ']
    if not all(col in df.columns for col in required_cols):
        print(f"   ‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω (–Ω–µ i2crm —Ñ–æ—Ä–º–∞—Ç)")
        return None
    
    df[['channel', 'direction']] = df['–ö–æ–Ω—Ç–µ–∫—Å—Ç'].apply(lambda x: pd.Series(parse_context(x)))
    df['sent_at'] = df['–ù–∞–ø–∏—Å–∞–Ω–æ'].apply(parse_timestamp)
    df = df.rename(columns={
        '–ö–∞–Ω–∞–ª': 'channel_name',
        '–ö–ª–∏–µ–Ω—Ç': 'client_identifier',
        '–°–æ–¥–µ—Ä–∂–∏–º–æ–µ': 'content',
        '–ö–æ–Ω—Ç–µ–∫—Å—Ç': 'raw_context'
    })
    
    df = df.dropna(subset=['client_identifier', 'sent_at'])
    print(f"   –í–∞–ª–∏–¥–Ω—ã—Ö: {len(df):,}")
    
    return df

def main():
    print("üöÄ –ò–º–ø–æ—Ä—Ç i2crm (chunked version)")
    print("="*80)
    
    # 1. –ß–∏—Ç–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
    excel_dir = Path("excel")
    excel_files = sorted(excel_dir.glob("*.xlsx"))
    
    print(f"\nüìÅ –ß—Ç–µ–Ω–∏–µ {len(excel_files)} —Ñ–∞–π–ª–æ–≤...")
    all_data = [process_excel_file(f) for f in excel_files]
    
    # –£–±–∏—Ä–∞–µ–º None (–ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã)
    all_data = [df for df in all_data if df is not None]
    
    combined_df = pd.concat(all_data, ignore_index=True)
    print(f"\n‚úÖ –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {len(combined_df):,}")
    
    # 2. –°–æ–∑–¥–∞–µ–º –í–°–ï –¥–∏–∞–ª–æ–≥–∏ –æ–¥–∏–Ω —Ä–∞–∑
    print("\n" + "="*80)
    print("üìã –°–û–ó–î–ê–ù–ò–ï –í–°–ï–• –î–ò–ê–õ–û–ì–û–í")
    print("="*80)
    
    grouped = combined_df.groupby(['channel', 'client_identifier']).agg({
        'sent_at': ['min', 'max', 'count'],
        'direction': lambda x: (x == 'incoming').sum(),
        'channel_name': 'first'
    }).reset_index()
    
    grouped.columns = [
        'channel', 'client_identifier',
        'first_message_at', 'last_message_at', 'total_messages',
        'incoming_count', 'channel_name'
    ]
    grouped['outgoing_count'] = grouped['total_messages'] - grouped['incoming_count']
    
    print(f"–ù–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤: {len(grouped):,}")
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∏ —Å–æ–∑–¥–∞–µ–º –¥–∏–∞–ª–æ–≥–∏
    conn = psycopg2.connect(CONNECTION_STRING)
    cur = conn.cursor()
    
    conversations = []
    for _, row in grouped.iterrows():
        conv_id = str(uuid.uuid4())
        conversations.append((
            conv_id, row['channel'], row['channel_name'], row['client_identifier'],
            row['first_message_at'], row['last_message_at'],
            int(row['total_messages']), int(row['incoming_count']), int(row['outgoing_count'])
        ))
    
    insert_query = """
        INSERT INTO i2crm_conversations 
            (id, channel, channel_name, client_identifier, first_message_at, last_message_at,
             total_messages, incoming_count, outgoing_count)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
        ON CONFLICT (channel, client_identifier) DO NOTHING
    """
    
    execute_batch(cur, insert_query, conversations, page_size=1000)
    conn.commit()
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ –¥–∏–∞–ª–æ–≥–æ–≤: {len(conversations):,}")
    
    # –ü–æ–ª—É—á–∞–µ–º mapping
    cur.execute("SELECT channel, client_identifier, id FROM i2crm_conversations")
    conv_map = {(row[0], row[1]): row[2] for row in cur.fetchall()}
    print(f"‚úÖ Mapping —Å–æ–∑–¥–∞–Ω: {len(conv_map):,} –∑–∞–ø–∏—Å–µ–π")
    
    cur.close()
    conn.close()
    
    # 3. –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ú–ê–õ–ï–ù–¨–ö–ò–ú–ò –ß–ê–ù–ö–ê–ú–ò
    print("\n" + "="*80)
    print("üí¨ –ò–ú–ü–û–†–¢ –°–û–û–ë–©–ï–ù–ò–ô (–º–∞–ª–µ–Ω—å–∫–∏–µ —á–∞–Ω–∫–∏)")
    print("="*80)
    
    # –î–æ–±–∞–≤–ª—è–µ–º conversation_id
    combined_df['conversation_id'] = combined_df.apply(
        lambda row: conv_map.get((row['channel'], row['client_identifier'])),
        axis=1
    )
    
    # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ conversation_id
    combined_df = combined_df.dropna(subset=['conversation_id'])
    print(f"–°–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞: {len(combined_df):,}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
    conn = psycopg2.connect(CONNECTION_STRING)
    cur = conn.cursor()
    cur.execute("SELECT COUNT(*) FROM i2crm_messages")
    already_imported = cur.fetchone()[0]
    cur.close()
    conn.close()
    
    if already_imported > 0:
        print(f"‚ö†Ô∏è  –£–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {already_imported:,} —Å–æ–æ–±—â–µ–Ω–∏–π")
        print(f"   –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—ã–µ {already_imported:,} —Å—Ç—Ä–æ–∫...")
        combined_df = combined_df.iloc[already_imported:]
        print(f"   –û—Å—Ç–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å: {len(combined_df):,}")
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–∞–ª–µ–Ω—å–∫–∏–º–∏ —á–∞—Å—Ç—è–º–∏
    CHUNK_SIZE = 500  # –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ —á–∞–Ω–∫–∏ –¥–ª—è Neon
    MAX_RETRIES = 5
    
    total = len(combined_df)
    imported = 0
    
    for start_idx in range(0, total, CHUNK_SIZE):
        end_idx = min(start_idx + CHUNK_SIZE, total)
        chunk = combined_df.iloc[start_idx:end_idx]
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        messages = []
        for _, row in chunk.iterrows():
            messages.append((
                str(uuid.uuid4()),
                row['conversation_id'],
                row['channel'],
                row['channel_name'],
                row['client_identifier'],
                row['content'],
                row['direction'],
                row['sent_at'],
                row['raw_context']
            ))
        
        # –ü—Ä–æ–±—É–µ–º –≤—Å—Ç–∞–≤–∏—Ç—å —Å retry
        for attempt in range(MAX_RETRIES):
            try:
                conn = psycopg2.connect(CONNECTION_STRING)
                cur = conn.cursor()
                
                insert_query = """
                    INSERT INTO i2crm_messages 
                        (id, conversation_id, channel, channel_name, client_identifier,
                         content, direction, sent_at, raw_context)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                """
                
                execute_batch(cur, insert_query, messages, page_size=100)
                conn.commit()
                cur.close()
                conn.close()
                
                imported += len(messages)
                
                if (start_idx // CHUNK_SIZE) % 10 == 0:  # –ö–∞–∂–¥—ã–µ 10 —á–∞–Ω–∫–æ–≤
                    progress = (imported / total) * 100
                    print(f"   {imported:,} / {total:,} ({progress:.1f}%)")
                
                break
                
            except Exception as e:
                if attempt < MAX_RETRIES - 1:
                    print(f"   ‚ö†Ô∏è  Retry {attempt + 1}/{MAX_RETRIES} –¥–ª—è —á–∞–Ω–∫–∞ {start_idx}")
                    try:
                        conn.close()
                    except:
                        pass
                    time.sleep(2)
                else:
                    print(f"   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —á–∞–Ω–∫ {start_idx}: {e}")
                    raise
        
        # –ú–∞–ª–µ–Ω—å–∫–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏
        time.sleep(0.1)
    
    print(f"\n‚úÖ –ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω: {imported:,} —Å–æ–æ–±—â–µ–Ω–∏–π")
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    conn = psycopg2.connect(CONNECTION_STRING)
    cur = conn.cursor()
    
    cur.execute("SELECT COUNT(*) FROM i2crm_conversations")
    final_convs = cur.fetchone()[0]
    
    cur.execute("SELECT COUNT(*) FROM i2crm_messages")
    final_msgs = cur.fetchone()[0]
    
    cur.execute("SELECT channel, COUNT(*) FROM i2crm_messages GROUP BY channel")
    by_channel = dict(cur.fetchall())
    
    cur.close()
    conn.close()
    
    print("\n" + "="*80)
    print("üìä –ò–¢–û–ì–û")
    print("="*80)
    print(f"–î–∏–∞–ª–æ–≥–æ–≤: {final_convs:,}")
    print(f"–°–æ–æ–±—â–µ–Ω–∏–π: {final_msgs:,}")
    print(f"\n–ü–æ –∫–∞–Ω–∞–ª–∞–º:")
    for channel, count in by_channel.items():
        print(f"  ‚Ä¢ {channel}: {count:,}")
    print("="*80)

if __name__ == "__main__":
    main()

