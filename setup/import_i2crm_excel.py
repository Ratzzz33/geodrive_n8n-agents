#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel –≤—ã–≥—Ä—É–∑–æ–∫ i2crm –≤ PostgreSQL

–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç:
- Telegram —Å–æ–æ–±—â–µ–Ω–∏—è (71k)
- WhatsApp —Å–æ–æ–±—â–µ–Ω–∏—è (424k, —Ä–∞–∑–±–∏—Ç–æ –Ω–∞ 3 —Ñ–∞–π–ª–∞)
–í—Å–µ–≥–æ: 495,457 —Å–æ–æ–±—â–µ–Ω–∏–π

–°—Ç—Ä—É–∫—Ç—É—Ä–∞:
1. –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ –¥–∏–∞–ª–æ–≥–∞–º (–∫–ª–∏–µ–Ω—Ç + –∫–∞–Ω–∞–ª)
2. –°–æ–∑–¥–∞–µ—Ç –∑–∞–ø–∏—Å–∏ –≤ i2crm_conversations
3. –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ i2crm_messages
"""

import sys
import io
import pandas as pd
import os
from pathlib import Path
from datetime import datetime
import psycopg2
from psycopg2.extras import execute_batch
import uuid

# –§–∏–∫—Å –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è Windows
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# Connection string –∏–∑ .env –∏–ª–∏ –Ω–∞–ø—Ä—è–º—É—é
CONNECTION_STRING = "postgresql://neondb_owner:npg_cHIT9Kxfk1Am@ep-rough-heart-ahnybmq0-pooler.c-3.us-east-1.aws.neon.tech/neondb?sslmode=require"

def parse_context(context_str):
    """
    –ü–∞—Ä—Å–∏—Ç –∫–æ–ª–æ–Ω–∫—É '–ö–æ–Ω—Ç–µ–∫—Å—Ç'
    –ü—Ä–∏–º–µ—Ä—ã: 'Telegram (–≤—Ö)', 'WhatsApp (–∏—Å—Ö)'
    
    Returns: (channel, direction)
        channel: 'telegram' –∏–ª–∏ 'whatsapp'
        direction: 'incoming' –∏–ª–∏ 'outgoing'
    """
    context_lower = context_str.lower()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–Ω–∞–ª
    if 'telegram' in context_lower:
        channel = 'telegram'
    elif 'whatsapp' in context_lower:
        channel = 'whatsapp'
    else:
        channel = 'unknown'
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
    if '(–≤—Ö)' in context_str or 'incoming' in context_lower:
        direction = 'incoming'
    elif '(–∏—Å—Ö)' in context_str or 'outgoing' in context_lower:
        direction = 'outgoing'
    else:
        direction = 'unknown'
    
    return channel, direction

def parse_timestamp(ts_str):
    """
    –ü–∞—Ä—Å–∏—Ç timestamp –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ '–ù–∞–ø–∏—Å–∞–Ω–æ'
    –§–æ—Ä–º–∞—Ç: '05.09.2024 11:50:22'
    
    Returns: datetime object
    """
    try:
        return datetime.strptime(ts_str, '%d.%m.%Y %H:%M:%S')
    except:
        return None

def process_excel_file(filepath):
    """
    –ß–∏—Ç–∞–µ—Ç Excel —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    """
    print(f"üìñ –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª: {os.path.basename(filepath)}")
    
    df = pd.read_excel(filepath)
    
    print(f"   –ü—Ä–æ—á–∏—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫: {len(df):,}")
    
    # –ü–∞—Ä—Å–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    df[['channel', 'direction']] = df['–ö–æ–Ω—Ç–µ–∫—Å—Ç'].apply(
        lambda x: pd.Series(parse_context(x))
    )
    
    # –ü–∞—Ä—Å–∏–º timestamp
    df['sent_at'] = df['–ù–∞–ø–∏—Å–∞–Ω–æ'].apply(parse_timestamp)
    
    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
    df = df.rename(columns={
        '–ö–∞–Ω–∞–ª': 'channel_name',
        '–ö–ª–∏–µ–Ω—Ç': 'client_identifier',
        '–°–æ–¥–µ—Ä–∂–∏–º–æ–µ': 'content',
        '–ö–æ–Ω—Ç–µ–∫—Å—Ç': 'raw_context'
    })
    
    # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    initial_count = len(df)
    df = df.dropna(subset=['client_identifier', 'sent_at'])
    removed = initial_count - len(df)
    
    if removed > 0:
        print(f"   ‚ö†Ô∏è  –£–±—Ä–∞–Ω–æ —Å—Ç—Ä–æ–∫ —Å –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏: {removed}")
    
    print(f"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫: {len(df):,}")
    
    return df

def create_conversations(conn, df):
    """
    –°–æ–∑–¥–∞–µ—Ç –∑–∞–ø–∏—Å–∏ –¥–∏–∞–ª–æ–≥–æ–≤ –≤ i2crm_conversations
    
    –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ: channel + client_identifier
    """
    print("\nüìã –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å–∏ –¥–∏–∞–ª–æ–≥–æ–≤...")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –¥–∏–∞–ª–æ–≥–∞–º
    grouped = df.groupby(['channel', 'client_identifier']).agg({
        'sent_at': ['min', 'max', 'count'],
        'direction': lambda x: (x == 'incoming').sum(),  # –í—Ö–æ–¥—è—â–∏—Ö
        'channel_name': 'first'  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    }).reset_index()
    
    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –ø–æ—Å–ª–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
    grouped.columns = [
        'channel', 'client_identifier', 
        'first_message_at', 'last_message_at', 'total_messages',
        'incoming_count', 'channel_name'
    ]
    
    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥—è—â–∏—Ö
    grouped['outgoing_count'] = grouped['total_messages'] - grouped['incoming_count']
    
    print(f"   –ù–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤: {len(grouped):,}")
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
    conversations = []
    for _, row in grouped.iterrows():
        conv_id = str(uuid.uuid4())
        conversations.append((
            conv_id,
            row['channel'],
            row['channel_name'],
            row['client_identifier'],
            row['first_message_at'],
            row['last_message_at'],
            int(row['total_messages']),
            int(row['incoming_count']),
            int(row['outgoing_count'])
        ))
    
    # –í—Å—Ç–∞–≤–ª—è–µ–º –≤ –ë–î (—Å ON CONFLICT DO UPDATE –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö)
    cur = conn.cursor()
    
    insert_query = """
        INSERT INTO i2crm_conversations 
            (id, channel, channel_name, client_identifier, first_message_at, last_message_at, 
             total_messages, incoming_count, outgoing_count)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
        ON CONFLICT (channel, client_identifier) 
        DO UPDATE SET
            first_message_at = LEAST(i2crm_conversations.first_message_at, EXCLUDED.first_message_at),
            last_message_at = GREATEST(i2crm_conversations.last_message_at, EXCLUDED.last_message_at),
            total_messages = i2crm_conversations.total_messages + EXCLUDED.total_messages,
            incoming_count = i2crm_conversations.incoming_count + EXCLUDED.incoming_count,
            outgoing_count = i2crm_conversations.outgoing_count + EXCLUDED.outgoing_count,
            updated_at = NOW()
        RETURNING id
    """
    
    execute_batch(cur, insert_query, conversations, page_size=1000)
    conn.commit()
    
    print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ/–æ–±–Ω–æ–≤–ª–µ–Ω–æ –¥–∏–∞–ª–æ–≥–æ–≤: {len(conversations):,}")
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ß–∏—Ç–∞–µ–º mapping –∏–∑ –ë–î –ü–û–°–õ–ï –≤—Å—Ç–∞–≤–∫–∏
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º WHERE —Å channel/client –∏–∑ –Ω–∞—à–µ–≥–æ grouped —á—Ç–æ–±—ã –Ω–µ —á–∏—Ç–∞—Ç—å —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
    channels = list(set(conv[1] for conv in conversations))
    clients = list(set(conv[3] for conv in conversations))
    
    # –ü–æ–ª—É—á–∞–µ–º ID –¥–ª—è —Ç–µ–∫—É—â–∏—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π (–ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± - —á–∏—Ç–∞–µ–º –≤—Å—ë, —Ç.–∫. –∏—Ö –Ω–µ–º–Ω–æ–≥–æ)
    cur.execute("""
        SELECT channel, client_identifier, id 
        FROM i2crm_conversations
    """)
    
    all_conv_map = {(row[0], row[1]): row[2] for row in cur.fetchall()}
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞—à–∏ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
    our_combos = set((conv[1], conv[3]) for conv in conversations)
    conv_map = {k: v for k, v in all_conv_map.items() if k in our_combos}
    
    print(f"   üìä –°–æ–∑–¥–∞–Ω–æ mapping –∑–∞–ø–∏—Å–µ–π: {len(conv_map):,}")
    
    if len(conv_map) != len(conversations):
        print(f"   ‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: mapping —Å–æ–¥–µ—Ä–∂–∏—Ç {len(conv_map)} –∑–∞–ø–∏—Å–µ–π, –æ–∂–∏–¥–∞–ª–æ—Å—å {len(conversations)}")
    
    cur.close()
    
    return conv_map

def import_messages(conn, df, conv_map):
    """
    –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –≤ i2crm_messages
    """
    print("\nüí¨ –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è...")
    
    # –î–æ–±–∞–≤–ª—è–µ–º conversation_id
    df['conversation_id'] = df.apply(
        lambda row: conv_map.get((row['channel'], row['client_identifier'])),
        axis=1
    )
    
    # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ conversation_id (–Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å)
    initial_count = len(df)
    df = df.dropna(subset=['conversation_id'])
    removed = initial_count - len(df)
    
    if removed > 0:
        print(f"   ‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π –±–µ–∑ –¥–∏–∞–ª–æ–≥–∞: {removed}")
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
    messages = []
    for _, row in df.iterrows():
        messages.append((
            str(uuid.uuid4()),
            row['conversation_id'],
            row['channel'],
            row['channel_name'],
            row['client_identifier'],
            row['content'] if pd.notna(row['content']) else '',
            row['direction'],
            row['sent_at'],
            row['raw_context']
        ))
    
    # –í—Å—Ç–∞–≤–ª—è–µ–º –±–∞—Ç—á–∞–º–∏ (–º–∞–ª–µ–Ω—å–∫–∏–µ –±–∞—Ç—á–∏ –¥–ª—è Neon serverless)
    cur = conn.cursor()
    
    insert_query = """
        INSERT INTO i2crm_messages 
            (id, conversation_id, channel, channel_name, client_identifier, 
             content, direction, sent_at, raw_context)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
    """
    
    total = len(messages)
    batch_size = 1000  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 5000 –¥–æ 1000 –¥–ª—è Neon
    max_retries = 3
    
    for i in range(0, total, batch_size):
        batch = messages[i:i+batch_size]
        
        # Retry –ª–æ–≥–∏–∫–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–±—Ä—ã–≤–æ–≤ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        for attempt in range(max_retries):
            try:
                execute_batch(cur, insert_query, batch, page_size=500)
                conn.commit()
                break
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—Å—Ç–∞–≤–∫–µ –±–∞—Ç—á–∞ {i}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}")
                    print(f"      {str(e)[:100]}")
                    # –ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–∞–µ–º—Å—è
                    try:
                        conn.close()
                    except:
                        pass
                    import time
                    time.sleep(2)
                    conn = psycopg2.connect(CONNECTION_STRING)
                    cur = conn.cursor()
                else:
                    print(f"   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—Å—Ç–∞–≤–∏—Ç—å –±–∞—Ç—á –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫")
                    raise
        
        progress = min(i + batch_size, total)
        print(f"   –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {progress:,} / {total:,} ({progress/total*100:.1f}%)")
    
    cur.close()
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    return conn
    
    print(f"   ‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {total:,}")

def main():
    excel_dir = Path("excel")
    
    if not excel_dir.exists():
        print("‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è 'excel' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return
    
    print("üöÄ –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ i2crm Excel –≤—ã–≥—Ä—É–∑–æ–∫")
    print("="*80)
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
    print("\nüì° –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL...")
    try:
        conn = psycopg2.connect(CONNECTION_STRING)
        print("   ‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ")
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
        return
    
    # –ß–∏—Ç–∞–µ–º –≤—Å–µ Excel —Ñ–∞–π–ª—ã
    excel_files = sorted(excel_dir.glob("*.xlsx"))
    print(f"\nüìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(excel_files)}")
    
    all_data = []
    
    for filepath in excel_files:
        try:
            df = process_excel_file(filepath)
            all_data.append(df)
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {filepath.name}: {e}")
            import traceback
            traceback.print_exc()
    
    if not all_data:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")
        conn.close()
        return
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
    print(f"\nüîÑ –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ {len(all_data)} —Ñ–∞–π–ª–æ–≤...")
    combined_df = pd.concat(all_data, ignore_index=True)
    print(f"   –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {len(combined_df):,}")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏–∞–ª–æ–≥–∏
    conv_map = create_conversations(conn, combined_df)
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è (–º–æ–∂–µ—Ç –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–∞—Ç—å—Å—è)
    conn = import_messages(conn, combined_df, conv_map)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "="*80)
    print("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("="*80)
    
    cur = conn.cursor()
    
    # –î–∏–∞–ª–æ–≥–∏
    cur.execute("SELECT COUNT(*) FROM i2crm_conversations")
    conv_count = cur.fetchone()[0]
    print(f"–î–∏–∞–ª–æ–≥–æ–≤ –≤ –ë–î: {conv_count:,}")
    
    cur.execute("SELECT channel, COUNT(*) FROM i2crm_conversations GROUP BY channel")
    for row in cur.fetchall():
        print(f"  ‚Ä¢ {row[0]}: {row[1]:,}")
    
    # –°–æ–æ–±—â–µ–Ω–∏—è
    cur.execute("SELECT COUNT(*) FROM i2crm_messages")
    msg_count = cur.fetchone()[0]
    print(f"\n–°–æ–æ–±—â–µ–Ω–∏–π –≤ –ë–î: {msg_count:,}")
    
    cur.execute("SELECT channel, COUNT(*) FROM i2crm_messages GROUP BY channel")
    for row in cur.fetchall():
        print(f"  ‚Ä¢ {row[0]}: {row[1]:,}")
    
    cur.execute("SELECT direction, COUNT(*) FROM i2crm_messages GROUP BY direction")
    print(f"\n–ü–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é:")
    for row in cur.fetchall():
        print(f"  ‚Ä¢ {row[0]}: {row[1]:,}")
    
    cur.close()
    conn.close()
    
    print("\n‚úÖ –ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print("="*80)

if __name__ == "__main__":
    main()

