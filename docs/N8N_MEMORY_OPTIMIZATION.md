# Оптимизация памяти n8n для параллельной работы вебхуков

## Проблема

При большом количестве входящих вебхуков n8n переполнял память (FATAL ERROR: Reached heap limit). Основная причина — сохранение всех данных выполнений с полным содержимым payload.

## Решение

### 1. Увеличение лимита памяти

**Было:** 2GB  
**Стало:** 4GB

```yaml
deploy:
  resources:
    limits:
      memory: 4G
    reservations:
      memory: 1G
```

### 2. Оптимизация сохранения данных

**Было:** `EXECUTIONS_DATA_SAVE_ON_SUCCESS=all` — сохранялись все данные выполнений  
**Стало:** `EXECUTIONS_DATA_SAVE_ON_SUCCESS=schema` — сохраняется только структура данных

Это **критически важно** для вебхуков, т.к.:
- Каждый вебхук сохраняет полный payload (может быть большим)
- При сотнях вебхуков в день это быстро заполняет память
- Schema сохраняет только структуру (типы, названия полей), без содержимого

### 3. Автоматическая очистка

**Настройки:**
- `EXECUTIONS_DATA_MAX_AGE=24` — удалять выполнения старше 24 часов (было 168 часов = 7 дней)
- `EXECUTIONS_DATA_PRUNE_MAX_COUNT=100` — максимум 100 выполнений в истории
- `EXECUTIONS_DATA_PRUNE=true` — автоматическая очистка включена

### 4. Оптимизация Node.js heap

```yaml
NODE_OPTIONS=--max-old-space-size=3584  # 3.5GB heap для Node.js
```

Это позволяет Node.js использовать до 3.5GB из 4GB доступной памяти.

## Автоматическая очистка памяти

### Скрипт: `setup/cleanup_n8n_executions.sh`

Удаляет старые выполнения из БД для освобождения памяти.

**Использование:**
```bash
./setup/cleanup_n8n_executions.sh
```

**Настройка cron (ежедневно в 3:00):**
```bash
0 3 * * * /root/geodrive_n8n-agents/setup/cleanup_n8n_executions.sh >> /var/log/n8n-cleanup.log 2>&1
```

### Применение оптимизаций

Скрипт: `setup/apply_n8n_memory_optimization.sh`

Применяет все изменения на сервере:
- Обновляет docker-compose.yml
- Перезапускает n8n
- Проверяет статус

## Почему так много весило?

### Проблема: `EXECUTIONS_DATA_SAVE_ON_SUCCESS=all`

При этой настройке n8n сохраняет:
- Полный payload каждого вебхука
- Все промежуточные данные между нодами
- Результаты выполнения всех нод
- Метаданные и заголовки

**Пример:**
- Вебхук с payload 1KB → сохранение ~5-10KB данных (payload + метаданные + структура)
- 100 вебхуков в день → ~500KB-1MB только payload
- За 7 дней (168 часов) → ~3.5MB-7MB только payload
- Но также сохраняются все промежуточные данные между нодами!

**Решение: `EXECUTIONS_DATA_SAVE_ON_SUCCESS=schema`**

Теперь сохраняется только:
- Структура данных (названия полей, типы)
- Метаданные выполнения (время, статус, длительность)
- **НЕ сохраняется** содержимое payload и промежуточные данные

**Результат:**
- Вебхук с payload 1KB → сохранение ~100-200 bytes (только структура)
- Сокращение использования памяти в **10-50 раз**

## Мониторинг

### Проверка использования памяти:
```bash
docker stats n8n --no-stream
```

### Проверка количества выполнений:
```bash
docker exec n8n psql -h $DB_HOST -U $DB_USER -d $DB_NAME -c "SELECT COUNT(*) FROM execution_entity;"
```

### Проверка размера данных:
```bash
docker exec n8n du -sh /home/node/.n8n
```

## Рекомендации

1. **Мониторинг:** Регулярно проверяйте использование памяти
2. **Очистка:** Настройте cron для автоматической очистки
3. **Логирование:** Если нужны полные данные для отладки, временно переключите на `all`, но не забывайте вернуть обратно
4. **Масштабирование:** При дальнейшем росте нагрузки рассмотрите использование Redis-очереди

## Ожидаемые результаты

- ✅ Увеличение лимита памяти до 4GB
- ✅ Сокращение использования памяти в 10-50 раз за счет сохранения только структуры
- ✅ Автоматическая очистка старых выполнений каждые 24 часа
- ✅ Бесперебойная параллельная обработка вебхуков
- ✅ Отсутствие переполнения памяти при пиковых нагрузках

